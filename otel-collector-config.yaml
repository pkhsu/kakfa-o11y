receivers:
  # Receive OTLP gRPC traces, metrics, and logs from applications
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Prometheus metrics receiver
  prometheus:
    config:
      scrape_configs:
        - job_name: 'kafka-exporter'
          static_configs:
            - targets: ['kafka-jmx-exporter:8080']
        - job_name: 'zookeeper-exporter'
          static_configs:
            - targets: ['zookeeper-jmx-exporter:8080']
        - job_name: 'otel-collector'
          static_configs:
            - targets: ['localhost:8888']

  # File log receiver for Docker container logs (including Kafka broker logs)
  filelog:
    include: [/var/log/containers/*/*-json.log]
    operators:
      - type: json_parser
        id: parser-docker
        parse_from: body
      - type: move
        from: attributes.log
        to: body

  # Docker stats receiver for container metrics
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    collection_interval: 10s

processors:
  # Batch processor for efficiency
  batch:
    timeout: 1s
    send_batch_size: 1024

  # Resource processor to add common attributes
  resource:
    attributes:
      - key: deployment.environment
        value: tutorial
        action: upsert
      - key: service.namespace
        value: kafka-tutorial
        action: upsert

  # resourcedetection processor to add container metadata
  resourcedetection:
    detectors: [env, docker]

  # Memory limiter to prevent out-of-memory
  memory_limiter:
    limit_mib: 512
    check_interval: 5s

  # Filter processor to clean up logs
  filter:
    logs:
      log_record:
        - 'IsMatch(body, ".*DEBUG.*") == false'
        - 'IsMatch(body, ".*TRACE.*") == false'

  # Attributes processor for logs enrichment
  attributes/logs:
    actions:
      - key: log.source
        value: kafka-tutorial
        action: upsert
      - key: log.collector
        value: otel-collector
        action: upsert

exporters:
  # Export to Prometheus for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"

  # Export traces to Tempo
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true

  # Export logs to Loki using the loki exporter
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    tls:
      insecure: true

  # Debug exporter (optional, for troubleshooting)
  debug:
    verbosity: basic

extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  pprof:
    endpoint: 0.0.0.0:1777
  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource]
      exporters: [otlp/tempo]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus]
      processors: [memory_limiter, batch, resource]
      exporters: [prometheus]

    # Logs pipeline
    logs:
      receivers: [otlp, filelog]
      processors: [memory_limiter, resourcedetection, filter, attributes/logs, batch, resource]
      exporters: [loki, debug]

  telemetry:
    logs:
      level: "info"
    metrics:
      address: 0.0.0.0:8888
