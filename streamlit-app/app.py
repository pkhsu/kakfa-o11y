import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import docker
import psutil
import os
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
import yaml
import json

# Page configuration
st.set_page_config(
    page_title="Kafka APM & Observability Demo",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state for language if it doesn't exist
if 'language' not in st.session_state:
    st.session_state['language'] = "English"

def set_language():
    """Callback function to update language in session state"""
    st.session_state.language = st.session_state.lang_selector

# Constants
GRAFANA_URL = os.getenv("GRAFANA_URL", "http://localhost:3000")
PROMETHEUS_URL = os.getenv("PROMETHEUS_URL", "http://localhost:9090")
OTEL_COLLECTOR_URL = os.getenv("OTEL_COLLECTOR_URL", "http://localhost:13133")

def get_docker_status():
    """Check Docker services status"""
    try:
        client = docker.from_env()
        containers = client.containers.list()
        services = {}
        for container in containers:
            name = container.name
            status = container.status
            services[name] = {
                'status': status,
                'image': container.image.tags[0] if container.image.tags else 'unknown',
                'ports': container.ports,
                'created': container.attrs['Created']
            }
        return services
    except Exception as e:
        return {"error": str(e)}

def check_service_health(url, timeout=5):
    """Check if a service is responding"""
    try:
        response = requests.get(url, timeout=timeout)
        return response.status_code == 200
    except:
        return False

def get_system_metrics():
    """Get basic system metrics"""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    return {
        'cpu_percent': cpu_percent,
        'memory_percent': memory.percent,
        'memory_available': memory.available / (1024**3),  # GB
        'disk_percent': disk.percent,
        'disk_free': disk.free / (1024**3)  # GB
    }

# Sidebar navigation
st.sidebar.title("ï¿½ï¿½ Demo Navigation")

# Language selection in the sidebar
st.sidebar.selectbox(
    "Language / èªè¨€:", 
    ["English", "ç¹é«”ä¸­æ–‡"], 
    key='lang_selector', 
    on_change=set_language
)

st.sidebar.markdown("---")

pages = {
    "ğŸ  Overview": "overview",
    "ğŸ—ï¸ Architecture": "architecture", 
    "ğŸ”§ Tech Stack": "tech_stack",
    "ğŸ“Š Monitoring Guide": "monitoring",
    "ğŸ® Demo Scenarios": "scenarios",
    "ğŸ“ˆ Live Status": "status",
    "ğŸ”— API Reference": "api",
    "ğŸ› ï¸ Troubleshooting": "troubleshooting"
}

selected_page = st.sidebar.radio("Select a page:", list(pages.keys()))
page_key = pages[selected_page]

# Use language from session state
language = st.session_state.language

# Main content area
if page_key == "overview":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("Kafka APM èˆ‡å¯è§€æ¸¬æ€§è§£æ±ºæ–¹æ¡ˆç¤ºç¯„")
        st.markdown("### Apache Kafka ç’°å¢ƒçš„æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½ç›£æ§ (APM) èˆ‡å¯è§€æ¸¬æ€§æ¨¡å¼ç¤ºç¯„")
        
        st.info("âš ï¸ **æ³¨æ„ï¼š** é€™æ˜¯ä¸€å€‹æ¦‚å¿µé©—è­‰çš„ç¤ºç¯„å°ˆæ¡ˆï¼Œä¾›å­¸ç¿’èˆ‡è©•ä¼°ä½¿ç”¨ï¼Œè‹¥è¦ç”¨æ–¼æ­£å¼ç’°å¢ƒéœ€è¦é€²è¡Œå¤§å¹…åº¦çš„ä¿®æ”¹ã€‚")
        
        st.markdown("#### ğŸ¯ ç¤ºç¯„åƒ¹å€¼")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            - **ç«¯åˆ°ç«¯å¯è¦‹æ€§** - æ¶µè“‹ç”Ÿç”¢è€…ã€æ¶ˆè²»è€…ã€ä»£ç†ä¼ºæœå™¨å’ŒåŸºç¤è¨­æ–½
            - **å¿«é€Ÿå•é¡Œè§£æ±º** - é€éé—œè¯çš„æŒ‡æ¨™ã€æ—¥èªŒå’Œè¿½è¹¤ç¸®çŸ­ä¿®å¾©æ™‚é–“
            """)
        with col2:
            st.markdown("""
            - **ä¸»å‹•ç›£æ§** - ææ—©åµæ¸¬æ•ˆèƒ½è¡°é€€å’Œå®¹é‡å•é¡Œ
            - **å¤šèªè¨€æ”¯æ´** - è·¨ Javaã€Python å’Œ Go æ‡‰ç”¨ç¨‹å¼çš„çµ±ä¸€å¯è§€æ¸¬æ€§
            """)
    else:
        st.title("Kafka APM & Observability Solution Demo")
        st.markdown("### A demonstration of Application Performance Monitoring (APM) and observability patterns for Apache Kafka environments")
        
        st.info("âš ï¸ **Note:** This is a proof-of-concept demo project for learning and evaluation purposes, not intended for production use without significant modifications.")
        
        st.markdown("#### ğŸ¯ Demo Value")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            - **End-to-End Visibility** - Full observability across producers, consumers, brokers, and infrastructure
            - **Rapid Problem Resolution** - Reduce MTTR from hours to minutes with correlated telemetry
            """)
        with col2:
            st.markdown("""
            - **Proactive Monitoring** - Early detection of performance degradation and capacity issues
            - **Multi-Language Support** - Unified observability across Java, Python, and Go applications
            """)
    
    # Quick Start section
    st.markdown("---")
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("### ğŸš€ å¿«é€Ÿé–‹å§‹")
        
        with st.expander("ğŸ“‹ å‰ç½®éœ€æ±‚æª¢æŸ¥"):
            st.code("""
# é©—è­‰ Docker å’Œ Compose å®‰è£
docker --version          # æ‡‰ç‚º 20.10+
docker compose version     # æ‡‰ç‚º v2.x+

# æª¢æŸ¥ç³»çµ±è³‡æº
free -h                    # é©—è­‰å¯ç”¨ RAM (éœ€è¦ 4GB+)
df -h                      # é©—è­‰ç£ç¢Ÿç©ºé–“ (éœ€è¦ 5GB+)
            """, language="bash")
        
        with st.expander("ğŸ”„ éƒ¨ç½²æ­¥é©Ÿ"):
            st.code("""
# 1. è¤‡è£½èˆ‡è¨­å®š
git clone <repository_url>
cd kakfa-o11y
chmod +x start.sh

# 2. å•Ÿå‹•ç’°å¢ƒ
./start.sh

# 3. é©—è­‰éƒ¨ç½²
docker compose ps
            """, language="bash")
    else:
        st.markdown("### ğŸš€ Quick Start")
        
        with st.expander("ğŸ“‹ Prerequisites Check"):
            st.code("""
# Verify Docker and Compose installation
docker --version          # Should be 20.10+
docker compose version     # Should be v2.x+

# Check system resources
free -h                    # Verify available RAM (4GB+ needed)
df -h                      # Verify disk space (5GB+ needed)
            """, language="bash")
        
        with st.expander("ğŸ”„ Deployment Steps"):
            st.code("""
# 1. Clone and Setup
git clone <repository_url>
cd kakfa-o11y
chmod +x start.sh

# 2. Start the Environment
./start.sh

# 3. Verify Deployment
docker compose ps
            """, language="bash")

elif page_key == "architecture":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ—ï¸ ç³»çµ±æ¶æ§‹")
        st.markdown("### å¯è§€æ¸¬æ€§æ¶æ§‹æ¦‚è¦½")
    else:
        st.title("ğŸ—ï¸ System Architecture")
        st.markdown("### Observability Architecture Overview")
    
    # Mermaid diagram
    st.markdown("""
    ```mermaid
    graph TB
        subgraph "Application Layer"
            JP[Java Producer]
            JC[Java Consumer]
            PP[Python Producer]
            PC[Python Consumer]
            GP[Go Producer]
            GC[Go Consumer]
        end
        
        subgraph "Kafka Cluster"
            K[Kafka Broker]
            Z[Zookeeper]
            JMX1[JMX Exporter - Kafka]
            JMX2[JMX Exporter - Zookeeper]
        end
        
        subgraph "Observability Pipeline"
            OC[OpenTelemetry Collector]
        end
        
        subgraph "Storage & Processing"
            P[Prometheus<br/>Metrics]
            L[Loki<br/>Logs]
            T[Tempo<br/>Traces]
        end
        
        subgraph "Visualization & Alerting"
            G[Grafana<br/>Dashboards & Alerts]
            SA[Streamlit<br/>Demo App]
        end
        
        JP --> |OTLP| OC
        JC --> |OTLP| OC
        PP --> |OTLP| OC
        PC --> |OTLP| OC
        GP --> |OTLP| OC
        GC --> |OTLP| OC
        
        JP -.-> |Kafka Protocol| K
        JC -.-> |Kafka Protocol| K
        PP -.-> |Kafka Protocol| K
        PC -.-> |Kafka Protocol| K
        GP -.-> |Kafka Protocol| K
        GC -.-> |Kafka Protocol| K
        
        JMX1 --> |Prometheus Format| OC
        JMX2 --> |Prometheus Format| OC
        K --> JMX1
        Z --> JMX2
        
        OC --> |Metrics| P
        OC --> |Logs| L
        OC --> |Traces| T
        
        P --> G
        L --> G
        T --> G
        
        G --> SA
    ```
    """)
    
    # Architecture principles
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("### ğŸ¯ é—œéµæ¶æ§‹åŸå‰‡")
        principles = [
            ("é›†ä¸­åŒ–æ”¶é›†", "ä½¿ç”¨å–®ä¸€ OpenTelemetry Collector æ”¶é›†æ‰€æœ‰é™æ¸¬è³‡æ–™"),
            ("å» å•†ä¸­ç«‹æ€§", "åŸºæ–¼æ¨™æº–çš„ OpenTelemetry å¯¦ä½œ"),
            ("å¯æ“´å±•æ€§", "å…·å‚™æŒä¹…åŒ–å„²å­˜çš„æ°´å¹³å¯æ“´å±•å…ƒä»¶"),
            ("å®‰å…¨æ€§", "å¯é…ç½®çš„èªè­‰èˆ‡åŠ å¯†æ”¯æ´"),
            ("é«˜å¯ç”¨æ€§", "å…·å‚™å¥åº·æª¢æŸ¥å’Œè‡ªå‹•å¾©åŸçš„å½ˆæ€§è¨­è¨ˆ")
        ]
    else:
        st.markdown("### ğŸ¯ Key Architecture Principles")
        principles = [
            ("Centralized Collection", "Single OpenTelemetry Collector for all telemetry data"),
            ("Vendor Neutrality", "Standards-based OpenTelemetry implementation"),
            ("Scalability", "Horizontally scalable components with persistent storage"),
            ("Security", "Configurable authentication and encryption support"),
            ("High Availability", "Resilient design with health checks and automatic recovery")
        ]
    
    for title, description in principles:
        st.markdown(f"**{title}:** {description}")

elif page_key == "tech_stack":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ”§ æŠ€è¡“å †ç–Š")
    else:
        st.title("ğŸ”§ Technology Stack")
    
    # Technology stack tables
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("### ğŸ“± æ‡‰ç”¨ç¨‹å¼ç›£æ¸¬å±¤")
        app_data = {
            "å…ƒä»¶": ["Java Apps", "Python Apps", "Go Apps"],
            "æŠ€è¡“": ["OpenTelemetry Java Agent", "OpenTelemetry Python SDK", "OpenTelemetry Go SDK"],
            "ç”¨é€”": ["è‡ªå‹•ç›£æ¸¬", "æ‰‹å‹•ç›£æ¸¬", "æ‰‹å‹•ç›£æ¸¬"],
            "ä¸»è¦ç‰¹è‰²": [
                "é›¶ç¨‹å¼ç¢¼ç›£æ¸¬ã€JVM æŒ‡æ¨™ã€Kafka å®¢æˆ¶ç«¯è¿½è¹¤",
                "è‡ªè¨‚æŒ‡æ¨™ã€çµæ§‹åŒ–æ—¥èªŒã€éåŒæ­¥æ”¯æ´",
                "é«˜æ•ˆèƒ½è¿½è¹¤ã€è‡ªè¨‚æŒ‡æ¨™ã€ä½è² æ“”"
            ]
        }
        
        st.markdown("### ğŸ“¨ è¨Šæ¯ä¸²æµå¹³å°")
        kafka_data = {
            "å…ƒä»¶": ["Apache Kafka", "Zookeeper", "JMX Exporters"],
            "æŠ€è¡“": ["Confluent Platform", "Apache Zookeeper", "Prometheus JMX Exporter"],
            "ç”¨é€”": ["è¨Šæ¯ä»£ç†ä¼ºæœå™¨", "å”èª¿æœå‹™", "æŒ‡æ¨™æ”¶é›†"],
            "ä¸»è¦ç‰¹è‰²": [
                "é«˜ååé‡ã€è€ä¹…æ€§ã€åŸºæ–¼åˆ†å€çš„æ“´å±•",
                "å¢é›†å”èª¿ã€é…ç½®ç®¡ç†",
                "ä»£ç†ä¼ºæœå™¨æŒ‡æ¨™ã€JVM çµ±è¨ˆã€ä¸»é¡ŒæŒ‡æ¨™"
            ]
        }
        
        st.markdown("### ğŸ‘ï¸ å¯è§€æ¸¬æ€§åŸºç¤è¨­æ–½")
        obs_data = {
            "å…ƒä»¶": ["OpenTelemetry Collector", "Prometheus", "Loki", "Tempo", "Grafana"],
            "æŠ€è¡“": ["OTEL Collector Contrib", "Prometheus TSDB", "Grafana Loki", "Grafana Tempo", "Grafana"],
            "ç”¨é€”": ["é™æ¸¬ç®¡é“", "æŒ‡æ¨™å„²å­˜", "æ—¥èªŒèšåˆ", "è¿½è¹¤å„²å­˜", "è¦–è¦ºåŒ–"],
            "ä¸»è¦ç‰¹è‰²": [
                "è³‡æ–™æ”¶é›†ã€è™•ç†ã€è·¯ç”±ã€åŒ¯å‡º",
                "æ™‚é–“åºåˆ—è³‡æ–™åº«ã€PromQL æŸ¥è©¢ã€å‘Šè­¦",
                "æ—¥èªŒç´¢å¼•ã€LogQL æŸ¥è©¢ã€æ¨™ç±¤çµ„ç¹”",
                "åˆ†æ•£å¼è¿½è¹¤ã€è¿½è¹¤é—œè¯ã€å–æ¨£",
                "å„€è¡¨æ¿ã€å‘Šè­¦ã€è³‡æ–™æ¢ç´¢"
            ]
        }
    else:
        st.markdown("### ğŸ“± Application Instrumentation Layer")
        app_data = {
            "Component": ["Java Apps", "Python Apps", "Go Apps"],
            "Technology": ["OpenTelemetry Java Agent", "OpenTelemetry Python SDK", "OpenTelemetry Go SDK"],
            "Purpose": ["Auto-instrumentation", "Manual instrumentation", "Manual instrumentation"],
            "Key Features": [
                "Zero-code instrumentation, JVM metrics, Kafka client tracing",
                "Custom metrics, structured logging, async support",
                "High-performance tracing, custom metrics, low overhead"
            ]
        }
        
        st.markdown("### ğŸ“¨ Message Streaming Platform")
        kafka_data = {
            "Component": ["Apache Kafka", "Zookeeper", "JMX Exporters"],
            "Technology": ["Confluent Platform", "Apache Zookeeper", "Prometheus JMX Exporter"],
            "Purpose": ["Message Broker", "Coordination Service", "Metrics Collection"],
            "Key Features": [
                "High throughput, durability, partition-based scaling",
                "Cluster coordination, configuration management",
                "Broker metrics, JVM stats, topic metrics"
            ]
        }
        
        st.markdown("### ğŸ‘ï¸ Observability Infrastructure")
        obs_data = {
            "Component": ["OpenTelemetry Collector", "Prometheus", "Loki", "Tempo", "Grafana"],
            "Technology": ["OTEL Collector Contrib", "Prometheus TSDB", "Grafana Loki", "Grafana Tempo", "Grafana"],
            "Purpose": ["Telemetry Pipeline", "Metrics Storage", "Log Aggregation", "Trace Storage", "Visualization"],
            "Key Features": [
                "Data collection, processing, routing, export",
                "Time-series database, PromQL queries, alerting",
                "Log indexing, LogQL queries, label-based organization",
                "Distributed tracing, trace correlation, sampling",
                "Dashboards, alerting, data exploration"
            ]
        }
    
    st.dataframe(pd.DataFrame(app_data), use_container_width=True)
    st.dataframe(pd.DataFrame(kafka_data), use_container_width=True)
    st.dataframe(pd.DataFrame(obs_data), use_container_width=True)

elif page_key == "monitoring":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ“Š ç›£æ§èˆ‡å¯è§€æ¸¬æ€§æŒ‡å—")
        st.markdown("### é å»ºå„€è¡¨æ¿èˆ‡ç›£æ§å ´æ™¯")
    else:
        st.title("ğŸ“Š Monitoring & Observability Guide")
        st.markdown("### Pre-Built Dashboards & Monitoring Scenarios")
    
    # Dashboard access
    st.markdown("#### ğŸ›ï¸ Dashboard Access")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ”— Grafana Dashboard"):
            st.markdown(f"[Open Grafana]({GRAFANA_URL})")
            st.info("Default credentials: admin/admin")
    
    with col2:
        if st.button("ğŸ“ˆ Prometheus"):
            st.markdown(f"[Open Prometheus]({PROMETHEUS_URL})")
    
    with col3:
        if st.button("ğŸ” OTel Collector"):
            st.markdown(f"[Health Check]({OTEL_COLLECTOR_URL}/health)")
    
    # Key metrics
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("#### ğŸ“‹ éœ€è¦è§€å¯Ÿçš„é—œéµæŒ‡æ¨™")
        metrics_data = {
            "æŒ‡æ¨™åç¨±": [
                "kafka_messages_sent_total",
                "go.producer.messages_sent", 
                "kafka_network_request_total_time_ms_mean",
                "jvm_memory_used_bytes{area=\"heap\"}"
            ],
            "æè¿°": [
                "Python ç”Ÿç”¢è€…ååé‡",
                "Go ç”Ÿç”¢è€…ååé‡",
                "è«‹æ±‚å»¶é²",
                "è¨˜æ†¶é«”ä½¿ç”¨é‡"
            ],
            "æŸ¥è©¢": [
                "rate(kafka_messages_sent_total[1m])",
                "rate(go_producer_messages_sent[1m])",
                "kafka_network_request_total_time_ms_mean",
                "jvm_memory_used_bytes{area=\"heap\"}"
            ]
        }
    else:
        st.markdown("#### ğŸ“‹ Key Metrics to Watch")
        metrics_data = {
            "Metric Name": [
                "kafka_messages_sent_total",
                "go.producer.messages_sent", 
                "kafka_network_request_total_time_ms_mean",
                "jvm_memory_used_bytes{area=\"heap\"}"
            ],
            "Description": [
                "Python producer throughput",
                "Go producer throughput",
                "Request latency",
                "Memory usage"
            ],
            "Query": [
                "rate(kafka_messages_sent_total[1m])",
                "rate(go_producer_messages_sent[1m])",
                "kafka_network_request_total_time_ms_mean",
                "jvm_memory_used_bytes{area=\"heap\"}"
            ]
        }
    
    st.dataframe(pd.DataFrame(metrics_data), use_container_width=True)

elif page_key == "scenarios":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ® ç¤ºç¯„æƒ…å¢ƒ")
        st.markdown("### æŒ‡å°å¼é€æ­¥èªªæ˜")
    else:
        st.title("ğŸ® Demo Scenarios")
        st.markdown("### Guided Walkthrough")
    
    # Scenario tabs
    if language == "ç¹é«”ä¸­æ–‡":
        scenario_tabs = st.tabs(["æƒ…å¢ƒA: æ­£å¸¸ç‡Ÿé‹ç›£æ§", "æƒ…å¢ƒB: æ•ˆèƒ½æ•…éšœæ’é™¤", "æƒ…å¢ƒC: æ•…éšœå¾©åŸ", "æƒ…å¢ƒD: æ“´å±•ç‡Ÿé‹"])
    else:
        scenario_tabs = st.tabs(["Scenario A: Normal Operations", "Scenario B: Performance Troubleshooting", "Scenario C: Failure Recovery", "Scenario D: Scaling Operations"])
    
    with scenario_tabs[0]:
        if language == "ç¹é«”ä¸­æ–‡":
            st.markdown("#### ğŸ¯ å­¸ç¿’ç›®æ¨™")
            st.markdown("1. å•Ÿå‹•ç’°å¢ƒä¸¦è§€å¯ŸåŸºæº–æŒ‡æ¨™")
            st.markdown("2. ç€è¦½ Grafana å„€è¡¨æ¿")
            st.markdown("3. äº†è§£æ­£å¸¸æ•ˆèƒ½æ¨¡å¼")
            st.markdown("4. è¨­å®šåŸºæœ¬å‘Šè­¦è¦å‰‡")
            
            st.markdown("#### ğŸ“ æ“ä½œæ­¥é©Ÿ")
            st.code("""
# ç”¢ç”Ÿè² è¼‰ä¸¦è§€å¯Ÿ
docker compose logs -f python-producer
            """, language="bash")
        else:
            st.markdown("#### ğŸ¯ Learning Objectives")
            st.markdown("1. Start the environment and observe baseline metrics")
            st.markdown("2. Navigate through Grafana dashboards")
            st.markdown("3. Understand normal performance patterns")
            st.markdown("4. Set up basic alerting rules")
            
            st.markdown("#### ğŸ“ Steps")
            st.code("""
# Generate load and observe
docker compose logs -f python-producer
            """, language="bash")
    
    with scenario_tabs[1]:
        if language == "ç¹é«”ä¸­æ–‡":
            st.markdown("#### ğŸ¯ å­¸ç¿’ç›®æ¨™")
            st.markdown("1. å¼•å…¥äººå·¥å»¶é²")
            st.markdown("2. è§€å¯ŸæŒ‡æ¨™è¡°é€€")
            st.markdown("3. ä½¿ç”¨æ—¥èªŒè­˜åˆ¥æ ¹æœ¬åŸå› ")
            st.markdown("4. è¿½è¹¤è«‹æ±‚åœ¨ç³»çµ±ä¸­çš„æµç¨‹")
            
            st.markdown("#### ğŸ“ æ“ä½œæ­¥é©Ÿ")
            st.code("""
# æ¨¡æ“¬ç¶²è·¯å•é¡Œ
docker compose pause kafka
docker compose logs python-consumer
docker compose unpause kafka
            """, language="bash")
        else:
            st.markdown("#### ğŸ¯ Learning Objectives")
            st.markdown("1. Introduce artificial latency")
            st.markdown("2. Observe metric degradation")
            st.markdown("3. Use logs to identify root cause")
            st.markdown("4. Trace request flow through system")
            
            st.markdown("#### ğŸ“ Steps")
            st.code("""
# Simulate network issues
docker compose pause kafka
docker compose logs python-consumer
docker compose unpause kafka
            """, language="bash")

elif page_key == "status":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ“ˆ å³æ™‚ç³»çµ±ç‹€æ…‹")
    else:
        st.title("ğŸ“ˆ Live System Status")
    
    # Real-time status monitoring
    col1, col2 = st.columns(2)
    
    with col1:
        if language == "ç¹é«”ä¸­æ–‡":
            st.markdown("#### ğŸ³ Docker æœå‹™ç‹€æ…‹")
        else:
            st.markdown("#### ğŸ³ Docker Services Status")
        
        if st.button("ğŸ”„ Refresh Status"):
            services = get_docker_status()
            if "error" in services:
                st.error(f"Error: {services['error']}")
            else:
                status_data = []
                for name, info in services.items():
                    status_data.append({
                        "Service": name,
                        "Status": info['status'],
                        "Image": info['image'][:30] + "..." if len(info['image']) > 30 else info['image']
                    })
                st.dataframe(pd.DataFrame(status_data), use_container_width=True)
    
    with col2:
        if language == "ç¹é«”ä¸­æ–‡":
            st.markdown("#### ğŸ–¥ï¸ ç³»çµ±æŒ‡æ¨™")
        else:
            st.markdown("#### ğŸ–¥ï¸ System Metrics")
        
        if st.button("ğŸ“Š Check System"):
            metrics = get_system_metrics()
            
            # Create gauge charts
            fig_cpu = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = metrics['cpu_percent'],
                title = {'text': "CPU Usage (%)"},
                gauge = {'axis': {'range': [None, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [{'range': [0, 50], 'color': "lightgray"},
                                 {'range': [50, 80], 'color': "yellow"},
                                 {'range': [80, 100], 'color': "red"}],
                        'threshold': {'line': {'color': "red", 'width': 4},
                                     'thickness': 0.75, 'value': 90}}))
            fig_cpu.update_layout(height=300)
            st.plotly_chart(fig_cpu, use_container_width=True)
            
            st.metric("Memory Available", f"{metrics['memory_available']:.1f} GB", f"{metrics['memory_percent']:.1f}%")
            st.metric("Disk Free", f"{metrics['disk_free']:.1f} GB", f"{metrics['disk_percent']:.1f}%")

elif page_key == "api":
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ”— API åƒè€ƒ")
    else:
        st.title("ğŸ”— API Reference")
    
    # Service endpoints
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("#### ğŸŒ æœå‹™ç«¯é»")
        endpoints_data = {
            "ç«¯é»": [
                "http://localhost:4317",
                "http://localhost:4318", 
                "http://localhost:13133/health",
                "http://localhost:3000",
                "http://localhost:9090"
            ],
            "ç”¨é€”": [
                "OTLP gRPC",
                "OTLP HTTP",
                "å¥åº·æª¢æŸ¥",
                "Grafana ä»‹é¢",
                "Prometheus ä»‹é¢"
            ],
            "é€£æ¥åŸ ": [4317, 4318, 13133, 3000, 9090]
        }
    else:
        st.markdown("#### ğŸŒ Service Endpoints")
        endpoints_data = {
            "Endpoint": [
                "http://localhost:4317",
                "http://localhost:4318", 
                "http://localhost:13133/health",
                "http://localhost:3000",
                "http://localhost:9090"
            ],
            "Purpose": [
                "OTLP gRPC",
                "OTLP HTTP",
                "Health Check",
                "Grafana Interface",
                "Prometheus Interface"
            ],
            "Port": [4317, 4318, 13133, 3000, 9090]
        }
    
    st.dataframe(pd.DataFrame(endpoints_data), use_container_width=True)
    
    # API examples
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("#### ğŸ“‹ API ä½¿ç”¨ç¯„ä¾‹")
    else:
        st.markdown("#### ğŸ“‹ API Usage Examples")
    
    st.code("""
# Prometheus API - Query metrics
curl "http://localhost:9090/api/v1/query?query=kafka_messages_sent_total"

# Grafana API - Create dashboard
curl -X POST http://admin:admin@localhost:3000/api/dashboards/db \\
  -H "Content-Type: application/json" \\
  -d @dashboard.json
    """, language="bash")

else:  # troubleshooting
    if language == "ç¹é«”ä¸­æ–‡":
        st.title("ğŸ› ï¸ æ•…éšœæ’é™¤")
        st.markdown("### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ")
    else:
        st.title("ğŸ› ï¸ Troubleshooting")
        st.markdown("### Common Issues & Solutions")
    
    # Common issues table
    if language == "ç¹é«”ä¸­æ–‡":
        issues_data = {
            "å•é¡Œ": ["é«˜è¨˜æ†¶é«”ä½¿ç”¨é‡", "æ¶ˆè²»è€…å»¶é²", "ç¶²è·¯å•é¡Œ", "å„²å­˜å¢é•·"],
            "ç—‡ç‹€": ["OOM éŒ¯èª¤ã€å›æ‡‰ç·©æ…¢", "è™•ç†å»¶é²", "é€£ç·šé€¾æ™‚", "ç£ç¢Ÿç©ºé–“è­¦å‘Š"],
            "è§£æ±ºæ–¹æ¡ˆ": [
                "å¢åŠ å®¹å™¨è¨˜æ†¶é«”é™åˆ¶",
                "æ“´å±•æ¶ˆè²»è€…æˆ–æœ€ä½³åŒ–è™•ç†",
                "æª¢æŸ¥ Docker ç¶²è·¯ã€é˜²ç«ç‰†è¦å‰‡",
                "å¯¦ä½œä¿ç•™æ”¿ç­–"
            ]
        }
    else:
        issues_data = {
            "Issue": ["High Memory Usage", "Consumer Lag", "Network Issues", "Storage Growth"],
            "Symptoms": ["OOM errors, slow response", "Processing delays", "Connection timeouts", "Disk space warnings"],
            "Solution": [
                "Increase container memory limits",
                "Scale consumers or optimize processing",
                "Check Docker networking, firewall rules",
                "Implement retention policies"
            ]
        }
    
    st.dataframe(pd.DataFrame(issues_data), use_container_width=True)
    
    # Diagnostic commands
    if language == "ç¹é«”ä¸­æ–‡":
        st.markdown("#### ğŸ” è¨ºæ–·æŒ‡ä»¤")
    else:
        st.markdown("#### ğŸ” Diagnostic Commands")
    
    st.code("""
# View detailed logs
docker compose logs --tail=100 -f [service-name]

# Check resource usage
docker stats

# Kafka cluster status
docker compose exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092
    """, language="bash")

# Footer
st.sidebar.markdown("---")
if language == "ç¹é«”ä¸­æ–‡":
    st.sidebar.info("ğŸ’¡ **æç¤ºï¼š** é€™æ˜¯ä¸€å€‹æ•™è‚²ç¤ºç¯„å°ˆæ¡ˆï¼Œå±•ç¤ºç¾ä»£å¯è§€æ¸¬æ€§æ¨¡å¼")
else:
    st.sidebar.info("ğŸ’¡ **Tip:** This is an educational demo showcasing modern observability patterns")

st.sidebar.markdown(f"**Version:** Demo v1.0")
st.sidebar.markdown(f"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}")
