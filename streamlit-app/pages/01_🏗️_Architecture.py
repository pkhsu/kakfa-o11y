import streamlit as st
import pandas as pd

st.set_page_config(
    page_title="System Architecture",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

st.title("ğŸ—ï¸ System Architecture")
st.markdown("### Detailed Architecture Overview")

# Language selection
language = st.selectbox("Language / èªè¨€:", ["English", "ç¹é«”ä¸­æ–‡"])

if language == "ç¹é«”ä¸­æ–‡":
    st.markdown("### ğŸ¯ æ¶æ§‹å±¤ç´š")
    
    tab1, tab2, tab3, tab4 = st.tabs(["æ‡‰ç”¨ç¨‹å¼å±¤", "Kafka å¢é›†", "å¯è§€æ¸¬æ€§ç®¡é“", "å„²å­˜èˆ‡è¦–è¦ºåŒ–"])
    
    with tab1:
        st.markdown("#### ğŸ“± æ‡‰ç”¨ç¨‹å¼ç›£æ¸¬å±¤")
        st.markdown("""
        - **Java æ‡‰ç”¨ç¨‹å¼**: ä½¿ç”¨ OpenTelemetry Java Agent é€²è¡Œè‡ªå‹•ç›£æ¸¬
        - **Python æ‡‰ç”¨ç¨‹å¼**: ä½¿ç”¨ OpenTelemetry Python SDK é€²è¡Œæ‰‹å‹•ç›£æ¸¬  
        - **Go æ‡‰ç”¨ç¨‹å¼**: ä½¿ç”¨ OpenTelemetry Go SDK é€²è¡Œé«˜æ•ˆèƒ½ç›£æ¸¬
        """)
        
        st.code("""
        # Java è‡ªå‹•ç›£æ¸¬ç¯„ä¾‹
        java -javaagent:opentelemetry-javaagent.jar \\
             -Dotel.service.name=kafka-producer \\
             -jar producer.jar
        """, language="bash")
    
    with tab2:
        st.markdown("#### ğŸ”„ Kafka å¢é›†å±¤")
        st.markdown("""
        - **Kafka Broker**: è¨Šæ¯ä»£ç†ä¼ºæœå™¨ï¼Œè™•ç†ç”Ÿç”¢è€…å’Œæ¶ˆè²»è€…è«‹æ±‚
        - **Zookeeper**: å¢é›†å”èª¿æœå‹™ï¼Œç®¡ç† broker ç‹€æ…‹å’Œé…ç½®
        - **JMX Exporters**: å°‡ JMX æŒ‡æ¨™è½‰æ›ç‚º Prometheus æ ¼å¼
        """)
        
        st.info("ğŸ’¡ æ­¤ç¤ºç¯„ä½¿ç”¨å–®ä¸€ broker é…ç½®ï¼Œé©ç”¨æ–¼å­¸ç¿’å’Œæ¸¬è©¦ç›®çš„")
    
    with tab3:
        st.markdown("#### ğŸ” å¯è§€æ¸¬æ€§ç®¡é“")
        st.markdown("""
        **OpenTelemetry Collector** ä½œç‚ºä¸­å¤®æ”¶é›†é»ï¼š
        - æ¥æ”¶ä¾†è‡ªæ‰€æœ‰æ‡‰ç”¨ç¨‹å¼çš„ OTLP è³‡æ–™
        - è™•ç†å’Œè·¯ç”±é™æ¸¬è³‡æ–™åˆ°é©ç•¶çš„å¾Œç«¯
        - æ”¯æ´å¤šç¨®åŒ¯å‡ºå™¨å’Œè™•ç†å™¨
        """)
        
        st.code("""
        # OTLP é…ç½®ç¯„ä¾‹
        receivers:
          otlp:
            protocols:
              grpc:
                endpoint: 0.0.0.0:4317
              http:
                endpoint: 0.0.0.0:4318
        """, language="yaml")
    
    with tab4:
        st.markdown("#### ğŸ“Š å„²å­˜èˆ‡è¦–è¦ºåŒ–")
        st.markdown("""
        - **Prometheus**: æ™‚é–“åºåˆ—æŒ‡æ¨™å„²å­˜
        - **Loki**: æ—¥èªŒèšåˆå’ŒæŸ¥è©¢
        - **Tempo**: åˆ†æ•£å¼è¿½è¹¤å„²å­˜
        - **Grafana**: çµ±ä¸€è¦–è¦ºåŒ–å’Œå‘Šè­¦å¹³å°
        """)

else:
    st.markdown("### ğŸ¯ Architecture Layers")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Application Layer", "Kafka Cluster", "Observability Pipeline", "Storage & Visualization"])
    
    with tab1:
        st.markdown("#### ğŸ“± Application Instrumentation Layer")
        st.markdown("""
        - **Java Applications**: Auto-instrumentation using OpenTelemetry Java Agent
        - **Python Applications**: Manual instrumentation using OpenTelemetry Python SDK
        - **Go Applications**: High-performance instrumentation using OpenTelemetry Go SDK
        """)
        
        st.code("""
        # Java auto-instrumentation example
        java -javaagent:opentelemetry-javaagent.jar \\
             -Dotel.service.name=kafka-producer \\
             -jar producer.jar
        """, language="bash")
    
    with tab2:
        st.markdown("#### ğŸ”„ Kafka Cluster Layer")
        st.markdown("""
        - **Kafka Broker**: Message broker handling producer and consumer requests
        - **Zookeeper**: Cluster coordination service managing broker state and configuration
        - **JMX Exporters**: Convert JMX metrics to Prometheus format
        """)
        
        st.info("ğŸ’¡ This demo uses a single broker configuration suitable for learning and testing")
    
    with tab3:
        st.markdown("#### ğŸ” Observability Pipeline")
        st.markdown("""
        **OpenTelemetry Collector** serves as the central collection point:
        - Receives OTLP data from all applications
        - Processes and routes telemetry data to appropriate backends
        - Supports multiple exporters and processors
        """)
        
        st.code("""
        # OTLP configuration example
        receivers:
          otlp:
            protocols:
              grpc:
                endpoint: 0.0.0.0:4317
              http:
                endpoint: 0.0.0.0:4318
        """, language="yaml")
    
    with tab4:
        st.markdown("#### ğŸ“Š Storage & Visualization")
        st.markdown("""
        - **Prometheus**: Time-series metrics storage
        - **Loki**: Log aggregation and querying
        - **Tempo**: Distributed tracing storage
        - **Grafana**: Unified visualization and alerting platform
        """)

# Data flow diagram
st.markdown("---")
if language == "ç¹é«”ä¸­æ–‡":
    st.markdown("### ğŸŒŠ è³‡æ–™æµæ¶æ§‹")
else:
    st.markdown("### ğŸŒŠ Data Flow Architecture")

st.markdown("""
```mermaid
flowchart LR
    A[Applications] --> B[OTLP]
    B --> C[OpenTelemetry Collector]
    C --> D[Prometheus]
    C --> E[Loki]
    C --> F[Tempo]
    D --> G[Grafana]
    E --> G
    F --> G
    G --> H[Alerts]
    G --> I[Dashboards]
```
""")

# Performance characteristics
st.markdown("---")
if language == "ç¹é«”ä¸­æ–‡":
    st.markdown("### âš¡ æ•ˆèƒ½ç‰¹æ€§")
    
    perf_data = {
        "å…ƒä»¶": ["Java Producer", "Python Producer", "Go Producer"],
        "é æœŸååé‡": ["5,000-10,000 msg/sec", "1,000-2,000 msg/sec", "8,000-15,000 msg/sec"],
        "å»¶é² (P95)": ["< 50ms", "< 100ms", "< 30ms"],
        "è¨˜æ†¶é«”ä½¿ç”¨": ["~500MB", "~200MB", "~100MB"]
    }
else:
    st.markdown("### âš¡ Performance Characteristics")
    
    perf_data = {
        "Component": ["Java Producer", "Python Producer", "Go Producer"],
        "Expected Throughput": ["5,000-10,000 msg/sec", "1,000-2,000 msg/sec", "8,000-15,000 msg/sec"],
        "Latency (P95)": ["< 50ms", "< 100ms", "< 30ms"],
        "Memory Usage": ["~500MB", "~200MB", "~100MB"]
    }

st.dataframe(pd.DataFrame(perf_data), use_container_width=True) 